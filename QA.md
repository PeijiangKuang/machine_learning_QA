## 离散化
### 离散化的方式
1. 等距离散, 等量离散
2. 卡方离散 **
3. 树模型离散
### 等距离散 / 等量离散 适合怎样的数据分布？分多少区间合适？
1. 对于类高斯分布的数据，采用等距, 等量离散差异不大；
2. 对于长尾分布的数据，采用等量离散；
3. 区间的个数，由训练平台 跟 每个区间的样本数决定；
** 核心的思想是，希望能将数据区分开来，并且该区间的参数得到充分的训练；
** 对于长尾分布的数据，采用等距离散的结果是数据无法得到有效的区分；
### 等距离散 / 等量离散 和 树离散 有哪些区别？
1. 等距离散，等量离散 没有结合label信息；树离散通过监督的方式先训练树模型，再根据叶子节点进行离散，因此包含了label信息；

## 平滑
### 点击率等指标需要怎么平滑？
1. 贝叶斯平滑，smooth_ctr = (click + alpha) / (expo + beta)
** 这里的alpha，beta应该要考虑到，不同分类的物品应该区别对待；
** alpha，beta应该用中位数，因为推荐系统中曝光，点击的分布常常是长尾分布；

## 正则化
### 正则化一般有哪些？
1. l1正则 参数绝对值求和
2. l2正则 参数平方值求和
### l1 / l2 正则的差别在哪？
1. loss 的定义不一样，一个是绝对值求和，一个是平方值求和
2. l1 更容易产生稀疏解，l2 更容易产生平滑解
### 为什么l1容易产生稀疏解？
1. 画图解释
2. l1 正则产生的梯度是一个固定值，当训练到后期的时候，l1产生的梯度作主导，使得参数更容易趋向于0值
l2 正则产生的梯度是参数的一半，当训练到后期的时候，l2产生的梯度越来越弱，相比而言更不容易产生稀疏解

## FTRL
### FTRL 是什么？为什么会有FTRL？
1. FTRL 是一种梯度更新的方法，具体而言，是一种在线梯度更新的方法
2. 因为OGD中的SGD不能很好的产生有效的稀疏解，所以需要对其进行优化，FTRL就是优化后的产物
### FTRL 需要保存什么参数？
FTRL的原理：
w* = argmin {g(1:s) w + lambda1 |w| + 1/2 lambda2 pow(w, 2) + 1/2 sum sigma(s) pow(w - w_s, 2)}
sigma(s) 是 前后两次迭代的learning rate的倒数的差异
分解成几块：
1. l1正则
2. l2正则
3. 最优解不应离迭代过的参数太远
最优解的显式解：

w* = 0， if |zi(t)| < lambda1

w* = -(zi(t) - lambda1 * sgn(zi(t))) / (lambda2 + sum sigma(s))，other

其中：zi(t) = zi(t-1) + gi - sigma(t) w(t)

所以，在FTRL实现的思路上，需要求解一下几个参数：
1. 求sigma
2. 求zi
3. 求累计梯度

## xgboost
### xgboost的原理是什么？
1. 通过对loss function进行泰勒二次展开后，保留至二阶项，将问题转化成求解多元二次函数的问题
### xgboost的优化点有哪些？
1. 对比gbdt，用了二阶项的信息
2. 能有效处理缺失值
3. shrinkage，使得训练不容易过拟合
### xgboost的结点是怎么分裂的？
1. 全局算法：在树结构构建的初始阶段，计算出所有的候选分割点，在随后的建树过程中，无论构建哪一层，都使用同样的候选分割点，这种方法全局只需要计算一次，步骤更少，但是需要计算出的候选节点更多才能保证精度。
2. 局部算法：每一次分裂都重新计算候选分割点，计算步骤更多，但是总的需要计算的候选节点更少，适用于更深的树的构建。
### gbdt 和 xgboost的区别在哪？
1. 一阶 和 二阶信息的差异


## LR
### LR的loss function是什么？
### LR是线性模型，怎样体现非线性性？
### LR为什么不用tanh？

## fm (factorization machine)
### fm 的表达式是什么？
### fm 的loss function是什么？
### fm 和 lr 的区别在哪？

## 梯度下降
### 梯度下降法有哪些？优化点在哪，区别在哪？
### 不同的梯度下降法最终的结果有什么差异？1. 权重，2. loss，3. 稀疏度

## 模型方差 和 偏差
### 方差是什么？偏差是什么？
### 模型融合有哪些方法？从方差和偏差的角度怎么看模型融合能给最终结果带来提升？

## 类别问题
### 类别不平衡会导致什么问题，怎么解决？
### 如果希望不同类之间的深度特征有更大的区分性（类间距离大，类内距离小），怎么解决?
### 类别中有噪声数据，怎么解决？

## 异常点
### 异常点检测都有哪些方法？
### pca能不能做异常点检测？
### isolation forest的原理是什么？适合怎样的数据？

## 聚类
### kmeans 及其变形。kmeans的优缺点
### 密度聚类DBSCAN的原理，跟kmeans相比它有什么优点

## 推荐冷启动
### 物品冷启动 和 用户冷启动 需要怎么做？

## 推荐规则层
### 怎么平衡多样性和精准性

## 最大的k个数，各种解法的复杂度

